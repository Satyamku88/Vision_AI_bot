# ðŸ¤– VisionBot - Offline AI Voice & Vision Assistant

**VisionBot** is a smart AI assistant that runs fully offline on your Windows 11 PC. It can **see objects**, **recognize faces**, **listen to voice commands**, and respond using an **offline LLM** like DeepSeek. It even has a built-in **chat UI** that logs your interactions!

---

## ðŸ“¹ What It Can Do

- ðŸŽ¤ Voice command like â€œWhat do you see?â€
- ðŸ‘€ Detect objects from **live camera** (YOLOv8)
- ðŸ˜Š Recognize known faces and greet them (e.g., "Hi Satyam!")
- ðŸ§  Answer intelligently using **DeepSeek** model via **Ollama**
- ðŸ’¬ Chat UI with history (web-based interface)
- ðŸ“¦ Runs fully offline â€” no internet needed after setup

---

## ðŸ“· Testing Video

VIDEO LINK-
https://youtu.be/2Z7ZGd3dJwA

---

## ðŸ› ï¸ Tech Stack

| Component      | Technology                        |
|----------------|------------------------------------|
| ðŸŽ¥ Camera Feed | OpenCV                            |
| ðŸ§  Object AI   | YOLOv8 (Ultralytics)              |
| ðŸ˜Ž Face ID     | face_recognition + dlib           |
| ðŸŽ¤ Voice Input | Vosk (offline speech recognition) |
| ðŸ—£ï¸ Voice Output| pyttsx3 (TTS) or gTTS             |
| ðŸŒ Web UI      | Flask (API), HTML + JS (frontend) |
| ðŸ§  LLM Model   | Ollama + DeepSeek 14B             |

---

## ðŸ§¾ Requirements

- Windows 11 PC
- Python 3.10
- Camera + Microphone
- Git & Ollama installed

---

## ðŸ“ Folder Structure

```
vision_bot/
â”‚
â”œâ”€â”€ app.py                 # Main AI bot logic
â”œâ”€â”€ chat_api.py           # Flask backend for chat UI
â”œâ”€â”€ chat.html             # Frontend UI (opens in browser)
â”œâ”€â”€ known_faces/          # Store face images (e.g., satyam.jpg)
â”œâ”€â”€ vosk-model/           # Vosk voice recognition model
â”œâ”€â”€ templates/            # Flask HTML (optional)
â”œâ”€â”€ static/               # Custom styles/scripts (optional)
â”œâ”€â”€ requirements.txt
```

---

## ðŸ”½ Offline Model Downloads

### ðŸ§  DeepSeek via Ollama (LLM)
- [ðŸ”— Ollama Site](https://ollama.com)
- Install Ollama â†’ run model:
```bash
ollama run deepseek-r1:14b
```

### ðŸŽ¤ Vosk Voice Model (Offline)
- [ðŸ”— Download Vosk Small Model](https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip)
- Extract to: `vosk-model-small-en-us-0.15`

---

## ðŸš€ How to Run

### 1. Clone and activate environment
```bash
git clone https://github.com/yourusername/visionbot.git
cd visionbot
python -m venv venv
venv\Scripts\activate
```

### 2. Install requirements
```bash
pip install -r requirements.txt
```

> If `dlib` fails, download prebuilt `.whl` here:  
> [ðŸ”— Dlib Windows Binaries - Gohlke](https://www.lfd.uci.edu/~gohlke/pythonlibs/#dlib)

### 3. Run the bot
```bash
python app.py
```

### 4. Start web interface (optional)
```bash
python chat_api.py
```
Then open `chat.html` in your browser to view chat history.

---

## âœ… Features in Action

| Feature              | Status |
|----------------------|--------|
| Voice input (Vosk)   | âœ…     |
| Object detection     | âœ…     |
| Face recognition     | âœ…     |
| AI response (LLM)    | âœ…     |
| Web chat interface   | âœ…     |
| Fully offline mode   | âœ…     |

---

## ðŸ“· Known Faces Setup

Put your face images in the `known_faces/` folder with meaningful names like:

```
known_faces/
â”œâ”€â”€ satyam.jpg
â”œâ”€â”€ rohan.png
```

The bot will greet detected faces by filename!

---

## ðŸ§  Model Info

### DeepSeek LLM (used with Ollama)

- Name: `deepseek-r1:14b`
- Size: ~9 GB
- Offline model used for reasoning based on detected objects/faces
- Works fully offline using [Ollama](https://ollama.com/)

### YOLOv8 (Ultralytics)

- Used to detect real-world objects (pen, bottle, person, etc.)
- Model file: `yolov8n.pt` (auto-downloaded)

---

## ðŸ“¦ To-Do / Ideas

- [ ] Add emotion detection  
- [ ] Enable command training  
- [ ] Export to .exe app  
- [ ] Add face registration from webcam  
- [ ] Run on Raspberry Pi with Coral TPU  
- [ ] Add Telegram bot interface  

---

## ðŸ™‹â€â™‚ï¸ Author

**Satyam Kumar Kasyap**  
ðŸŽ“ BTech CSE | 2nd Year @ CUSAT  
ðŸ“¬ [GitHub](https://github.com/yourusername) â€¢ [LinkedIn](https://linkedin.com/in/yourusername)

---

## ðŸ“„ License

MIT License Â© 2025 [Satyam Kumar Kasyap](https://github.com/yourusername)

---

> âš¡ Feel free to fork, modify, or contribute â€” letâ€™s build offline AI assistants that can see, hear, and think!

```

---

Let me know if you want this file exported as `.md` and placed in your project folder directly. I can also help you generate a `requirements.txt` and upload demo screenshots or videos!
